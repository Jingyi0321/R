---
title: "Problem Set 5"
output:
  html_document:
    highlight: pygments
    theme: cerulean
---
-----

### NAME: Jingyi Fang
### USC ID: 8020938911
### People I discussed this with: Johnny Geng
### **DUE DATE: 2/28 at 11am **  

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#1. Preparations
##a)
We will need the `tidyverse` and `moderndive` packages for this problem set.  Please load these.
```{r question1a}
#install.packages("tidyverse")
#install.packages("moderndive")
library(tidyverse)
library(moderndive)
```
##b)
Download the csv file BikeCommute.csv from blackboard and put it in your Data folder, and write code that creates a data frame called `bike` with this data.
```{r question1b}
bike_path <- ("~/Documents/BUAD312/data/BikeCommute.csv")
bike <- read_csv(bike_path)

```

##c)
This data set was generated by someone biking to work each day.  Every morning he would flip a coin to decide whether to take his steel bike or his carbon bike. Although he was always biking to work, he would take slightly different routes, which is why the distances vary slightly.

How many rides did he take?  How many of them were on each kind of bike?

```{r question1c}
count(bike)

bike%>%
  group_by(Bike)%>%
  summarize(counts = n())


```

# He took 56 rides in total. He took 26 rides on his carbon bike, and he took 30 rides on his steel bike. 

#2. Looking at the response

Make a plot that shows the distribution of the variable `Minutes`.

```{r question2}
bike%>%
  ggplot(aes(x = Minutes))+
  geom_histogram(color = "white")+
  labs(x = "Minutes of ride", y = "Number of Rides", title = "The Distribution of Minutes of Ride")
```

#3. Train and test

As described in class, it is helpful to randomly split one's data set into a training set, which is used to fit various regression models, and a testing set, which is used to see how well these models perform on data that has not been "seen" by the models when they were being developed.

##a)
The following code adds a column called `training` of random 1s and 0s.
The probability of a 1 is 70% and the probability of a 0 is 30%. Uncomment the code.
```{r question3a}
set.seed(123)
bike <- bike %>% 
mutate(training = rbinom(n(), 1, prob = 0.7))

```

##b)
Create two data frames called `train_bike` and `test_bike`.  The data frame `train_bike` should contain all rows of the data frame `bike` with `training` being 1 and `test_bike` should be all other rows.
```{r question3b}
train_bike <- bike%>%
  filter(training == "1")

test_bike <- bike%>%
  filter(training == "0")

```

#4. Using bike type
##a)
Make a plot that helps one to see whether there might be a relationship between type of bike and the minutes of the ride. Only use the data in `train_bike`.
```{r question4a}
train_bike%>%
  ggplot(aes(x = Bike, y = Minutes))+
  geom_boxplot()+
  labs( x = "Type of Bike", y ="Minutes of Ride", title = "The relationship between the type of bike and the minutes of the ride")
```

##b)
Using the data in `train_bike`, fit a regression model to predict `Minutes` based on `Bike`.  Call your object `fit_bike`.  Use `get_regression_table` to show the output.
```{r question4b}
fit_bike <- lm(Minutes ~ Bike, data = train_bike)
get_regression_table(fit_bike)
```

##c)
Based on the output above, how many minutes would you predict a ride to be on the steel bike?  And what about on the carbon bike?

# On the steel bike, the minutes of the ride are predicted to be 106.539	minutes. On the carbon bike, the minutes of the ride are predicted to be 108.564	minutes.

##d)
Use the function `get_regression_points` to make predictions on the rides in the `test_bike` data frame.  Create a column called `abs_pred_err` that gives the absolute value of the difference between the predicted and actual minutes of each ride.  Which ride in the test set was predicted the worst (how long was it predicted to be and how long was it actually?)

```{r question4d}
fit_bike%>%
  get_regression_points(newdata = test_bike)%>%
  mutate(abs_pred_err = abs(Minutes_hat - Minutes))%>%
  arrange(desc(abs_pred_err))

```

# Ride ID 4 was predicted the worst. It was predicted to be 106.539 minutes, while it was actually 123.33 minutes. 

##e)
Calculate the average prediction error on the test set.  That is, the average of `abs_pred_err` on the test set.
```{r question4e}
fit_bike%>%
  get_regression_points(newdata = test_bike)%>%
  mutate(abs_pred_err = abs(Minutes_hat - Minutes))%>%
  summarize(avg_pred_err = mean(abs_pred_err))
```

#5. Using distance
##a)
Using `train_bike`, make a plot that would help us see visually whether `Minutes` could be predicted by `Distance`.
```{r question5a}
train_bike%>%
  ggplot(aes( x = Distance, y = Minutes))+
  geom_point()+
  geom_smooth(method = "lm", se = FALSE)+
  labs( x = "Distance of the ride", y = "Minutes of the ride", title = "The relationship between minutes of the ride and the distance of the ride")
```

##b)
Using `train_bike`, fit a model called `fit_distance` that uses `Distance` to predict `Minutes`.  Display the beta coefficients for this model.
```{r question5b}
fit_distance <- lm(Minutes ~ Distance, data = train_bike)
get_regression_table(fit_distance)
```
##c)
Calculate the average prediction error on the test set using this model.

```{r question5c}
fit_distance%>%
  get_regression_points(newdata = test_bike)%>%
  mutate(abs_pred_err = abs(Minutes_hat - Minutes))%>%
  summarize(avg_pred_err = mean(abs_pred_err))

```

#6. Parallel slopes model

##a)
Using `train_bike`, make a scatter plot that would help us see visually whether `Minutes` could be predicted by a combination of `Distance` and `Bike` using a parallel slopes model.

Hint: I recommend having `Bike` mapped to the color attribute.  Also, if you don't remember how to plot the parallel slopes model, reread Section 6.1.3 of the book.

```{r question6a}
train_bike%>%
  ggplot(aes(x = Distance, y = Minutes, color = Bike))+
  geom_point()+
  geom_parallel_slopes(se = FALSE)+
  labs (x = "Distance of the ride", y = "Minutes of the ride", title = "The relationship between minutes of the ride and a combination of distance of the ride and bike type")
  
```

##b)
Fit the parallel slopes model on `train_bike`, saving it to an object called `fit_parallel`.  Show the output of `get_regression_table`.

```{r question6b}
fit_parallel <- lm(Minutes ~ Distance + Bike, data = train_bike)
get_regression_table(fit_parallel)
```

##c)
Based on the above, fill in the blanks to give the equation of the line for carbon and the equation of the line for steel.

`fhat(Distance, Carbon) = _-109.421	_ + _7.886	_ * Distance`

`fhat(Distance, Steel) = _-104.143_ + _7.886	_ * Distance`

##d)
Calculate the average prediction error on the test set using this model.

```{r question6d}
fit_parallel%>%
get_regression_points(newdata = test_bike)%>%
  mutate(abs_pred_err = abs(Minutes_hat - Minutes))%>%
  summarize(avg_pred_err = mean(abs_pred_err))
```

#7. Interaction model

##a)
Using `train_bike`, make a scatter plot that would help us see visually whether `Minutes` could be predicted by a combination of `Distance` and `Bike` using an interaction model.

Hint: I recommend having Bike mapped to the color attribute.


```{r question7a}
train_bike%>%
  ggplot(aes(x = Distance, y = Minutes, color = Bike))+
  geom_point()+
  geom_smooth(method = "lm", se = FALSE)+
  labs (x = "Distance of the ride", y = "Minutes of the ride", title = "The relationship between minutes of the ride and a combination of distance of the ride and bike type")
```
##b)
Fit the interaction model on `train_bike`, saving it to an object called `fit_interaction`.  Show the output of `get_regression_table`.
```{r question7b}
fit_interaction <- lm(Minutes ~ Distance * Bike, data = train_bike)
get_regression_table(fit_interaction)
```
##c)
Based on the above, fill in the blanks to give the equation of the line for carbon and the equation of the line for steel.

`fhat(Distance, Carbon) = _-526.554	_ + _23.119	_ * Distance`

`fhat(Distance, Steel) = _-85.228_ + _7.185_ * Distance`

##d)
Calculate the average prediction error on the test set using this model.

```{r question7d}
fit_interaction%>%
  get_regression_points(newdata = test_bike)%>%
  mutate(abs_pred_err = abs(Minutes_hat - Minutes))%>%
  summarize(avg_pred_err = mean(abs_pred_err))
```

#8. Evaluating models
You have fit four models for predicting the amount of minutes of a ride.
Which of these models makes the best predictions on the test set?
Rank the models from best to worst.
# Interaction model, distance model, parallel model, bike type model.

#9. Predicting final exam grade
##a)
Download the csv file StatGrades.csv, put it in your Data folder, and write code that creates a data frame called `grades` with this data.
```{r question9a}
grades_path <- ("~/Documents/BUAD312/data/StatGrades.csv")
grades <- read_csv(grades_path)

```
This data set gives the grades of a set of students on two midterms and a final exam.

##b)
How many students are there?
```{r question9b}
count(grades)
```

# There are 50 students.

##c)
Make three plots that would help us to assess whether there is a relationship between 
 (i) the final exam score and Exam1,
 (ii) the final exam score and Exam2, and
 (iii) Exam2 and Exam1.
```{r question9c}
grades%>%
  ggplot(aes(x = Exam1, y = Final))+
  geom_point()+
  geom_smooth(method = "lm", se = FALSE)+
  labs(x = "Grades of Exam1", y = "Grades of Final", title = "The relationship between the final exam score and Exam1 score")

grades%>%
  ggplot(aes(x = Exam2, y = Final))+
  geom_point()+
  geom_smooth(method = "lm", se = FALSE)+
  labs(x = "Grades of Exam2", y = "Grades of Final", title = "The relationship between the final exam score and Exam2 score")

grades%>%
  ggplot(aes(x = Exam1, y = Exam2))+
  geom_point()+
  geom_smooth(method = "lm", se = FALSE)+
  labs(x = "Grades of Exam1", y = "Grades of Exam2", title = "The relationship between the Exam1 score and Exam2 score")


```

##d)
Create data frames called `train_grades` and `test_grades` in
which 60% of the students are assigned to the training set, and 
40% are assgined to the test set.
Hint: Modify the code from the bikes example above.  Be sure to include the `set.seed` line.

```{r question9d}
set.seed(123)
grades <- grades %>% 
  mutate(training = rbinom(n(), 1, prob = 0.6))

train_grades <- grades%>%
  filter(training == "1")

test_grades <- grades%>%
  filter(training == "0")

```

##e)
Fit a model using the training data that uses `Exam1` to predict `Final`.  On average, how many points off are this model's predictions for the final grade from the actual final grade for the students in the test set?

```{r question9e}
fit_Exam1 <- lm(Final ~ Exam1, data = train_grades)
fit_Exam1%>%
  get_regression_points(newdata = test_grades)%>%
  mutate(abs_pred_err = abs(Final_hat - Final))%>%
  summarize(avg_pred_err = mean(abs_pred_err))
```

##f)
Now fit a model (call it `fit_both`) that uses both `Exam1` and `Exam2` to predict `Final`.  Write out the equation of the regression plane  (filling in the blanks).

```{r question9f}
fit_both <- lm(Final ~ Exam1 + Exam2, data = train_grades)
get_regression_table(fit_both)  
```

`fhat(Exam1, Exam2) = 29.240_ + _0.517	_ * Exam1 + 0.171	__ * Exam2`

##g)
What is the interpretation for the slope on `Exam1`?
# 0.517	is the amount by which our prediction for Final score changes, on average, when we change Exam1 score by 1 point and keep Exam2 score fixed. 

##h)
Does adding the second exam score improve our ability to predict the final exam score?
```{r question9h}
fit_both <- lm(Final ~ Exam1 + Exam2, data = train_grades)
fit_both%>%
  get_regression_points(newdata = test_grades) %>%
  mutate(abs_pred_err = abs(Final_hat - Final))%>%
  summarize(avg_pred_err = mean(abs_pred_err))
```

# Since the average prediction error decreases, adding the second exam score improves our ability to predict the final exam score.

# What You Should Upload to Blackboard
Knit this .Rmd file into an html file. Upload both the .html and .Rmd files as a **single** .zip file to Blackboad by the due date. You can find instructions for making a .zip file on Piazza: https://piazza.com/class/k54ht3tm1d64u5?cid=11
